{
  "openapi": "3.1.0",
  "info": {
    "title": "The Jina Embedding Serving API",
    "description": "This is the UniversalAPI to access all the Jina embedding models",
    "version": "0.1.128"
  },
  "paths": {
    "/v1/embeddings": {
      "post": {
        "tags": [
          "embeddings"
        ],
        "summary": "Create Embedding",
        "description": "Create embedding representations of the given input texts.",
        "operationId": "create_embedding_v1_embeddings_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/EmbeddingInput"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Create embeddings",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ModelEmbeddingOutput"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        },
        "security": [
          {
            "HTTPBearer": []
          }
        ]
      }
    },
    "/v1/multi-vector": {
      "post": {
        "tags": [
          "multi-vector"
        ],
        "summary": "Create Multi Vector",
        "description": "Create multiple vector representations of the given input texts. One vector representation for each token in the input text.",
        "operationId": "create_multi_vector_v1_multi_vector_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TextEmbeddingAPIInput"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Create multi vector embeddings",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ColbertModelEmbeddingsOutput"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        },
        "security": [
          {
            "HTTPBearer": []
          }
        ]
      }
    },
    "/v1/rerank": {
      "post": {
        "tags": [
          "rerank"
        ],
        "summary": "Rank",
        "description": "Rank pairs.",
        "operationId": "rank_v1_rerank_post",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/RankAPIInput"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Rank output",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/RankingOutput"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        },
        "security": [
          {
            "HTTPBearer": []
          }
        ]
      }
    }
  },
  "components": {
    "schemas": {
      "EmbeddingInput": {
        "anyOf": [
          {
            "$ref": "#/components/schemas/TextEmbeddingInput"
          },
          {
            "$ref": "#/components/schemas/ImageEmbeddingInput"
          },
          {
            "$ref": "#/components/schemas/MixedEmbeddingInput"
          }
        ],
        "title": "EmbeddingInput"
      },
      "TextEmbeddingInput": {
        "properties": {
          "model": {
            "type": "string",
            "title": "Model",
            "description": "The identifier of the model.\n\nAvailable models and corresponding param size and dimension:\n- `jina-clip-v1`,\t223M,\t768\n- `jina-clip-v2`,\t865M,\t1024\n- `jina-embeddings-v2-base-en`,\t137M,\t768\n- `jina-embeddings-v2-base-es`,\t161M,\t768\n- `jina-embeddings-v2-base-de`,\t161M,\t768\n- `jina-embeddings-v2-base-zh`,\t161M,\t768\n- `jina-embeddings-v2-base-code`,\t137M,\t768\n- `jina-embeddings-v3`,\t570M,\t1024\n\nFor more information, please checkout our [technical blog](https://arxiv.org/abs/2307.11224).\n"
          },
          "input": {
            "anyOf": [
              {
                "items": {
                  "type": "string"
                },
                "type": "array"
              },
              {
                "type": "string"
              },
              {
                "items": {
                  "$ref": "#/components/schemas/api_schemas__embedding__TextDoc"
                },
                "type": "array"
              },
              {
                "$ref": "#/components/schemas/api_schemas__embedding__TextDoc"
              }
            ],
            "title": "Input",
            "description": "List of texts to embed"
          },
          "embedding_type": {
            "anyOf": [
              {
                "type": "string",
                "enum": [
                  "float",
                  "base64",
                  "binary",
                  "ubinary"
                ]
              },
              {
                "items": {
                  "type": "string",
                  "enum": [
                    "float",
                    "base64",
                    "binary",
                    "ubinary"
                  ]
                },
                "type": "array"
              }
            ],
            "title": "Embedding Type",
            "description": "The format in which you want the embeddings to be returned.Possible value are `float`, `base64`, `binary`, `ubinary` or a list containing any of them. Defaults to `float`"
          },
          "task": {
            "type": "string",
            "enum": [
              "retrieval.query",
              "retrieval.passage",
              "text-matching",
              "classification",
              "separation"
            ],
            "title": "Task",
            "description": "Used to convey intended downstream application to help the model produce better embeddings. Must be one of the following values:\n- \"retrieval.query\": Specifies the given text is a query in a search or retrieval setting.\n- \"retrieval.passage\": Specifies the given text is a document in a search or retrieval setting.\n- \"text-matching\": Specifies the given text is used for Semantic Textual Similarity.\n- \"classification\": Specifies that the embedding is used for classification.\n- \"separation\": Specifies that the embedding is used for clustering.\n"
          },
          "dimensions": {
            "type": "integer",
            "title": "Dimensions",
            "description": "Used to specify output embedding size. If set, output embeddings will be truncated to the size specified."
          },
          "normalized": {
            "type": "boolean",
            "title": "Normalized",
            "description": "Flag to determine if the embeddings should be normalized to have a unit L2 norm. Defaults to True",
            "default": true
          },
          "late_chunking": {
            "type": "boolean",
            "title": "Late Chunking",
            "description": "Flag to determine if late chunking is applied. If True, all the sentences in inputs will be concatenated and used as input for late chunking."
          },
          "truncate": {
            "type": "boolean",
            "title": "Truncate",
            "description": "Flag to determine if the text needs to be truncated when exceeding the maximum token length",
            "default": false
          }
        },
        "additionalProperties": false,
        "type": "object",
        "required": [
          "model",
          "input"
        ],
        "title": "TextEmbeddingInput",
        "description": "The input to the API for text embedding. OpenAI compatible",
        "example": {
          "model": "jina-embeddings-v3",
          "input": [
            "Hello, world!"
          ]
        }
      },
      "ImageEmbeddingInput": {
        "properties": {
          "model": {
            "type": "string",
            "title": "Model",
            "description": "The identifier of the model.\n\nAvailable models and corresponding param size and dimension:\n- `jina-clip-v1`,\t223M,\t768\n- `jina-clip-v2`,\t865M,\t1024\n\nFor more information, please checkout our [technical blog](https://arxiv.org/abs/2405.20204).\n"
          },
          "input": {
            "anyOf": [
              {
                "$ref": "#/components/schemas/api_schemas__image__ImageDoc"
              },
              {
                "items": {
                  "$ref": "#/components/schemas/api_schemas__image__ImageDoc"
                },
                "type": "array"
              }
            ],
            "title": "Input",
            "description": "List of images to embed"
          },
          "embedding_type": {
            "anyOf": [
              {
                "type": "string",
                "enum": [
                  "float",
                  "base64",
                  "binary",
                  "ubinary"
                ]
              },
              {
                "items": {
                  "type": "string",
                  "enum": [
                    "float",
                    "base64",
                    "binary",
                    "ubinary"
                  ]
                },
                "type": "array"
              }
            ],
            "title": "Embedding Type",
            "description": "The format in which you want the embeddings to be returned.Possible value are `float`, `base64`, `binary`, `ubinary` or a list containing any of them. Defaults to `float`"
          },
          "normalized": {
            "type": "boolean",
            "title": "Normalized",
            "description": "Flag to determine if the embeddings should be normalized to have a unit L2 norm",
            "default": true
          },
          "task": {
            "type": "string",
            "enum": [
              "retrieval.query",
              "retrieval.passage",
              "text-matching",
              "classification",
              "separation"
            ],
            "title": "Task",
            "description": "Used to convey intended downstream application to help the model produce better embeddings. Must be one of the following values:\n- \"retrieval.query\": Specifies the given text is a query in a search or retrieval setting.\n- \"retrieval.passage\": Specifies the given text is a document in a search or retrieval setting.\n- \"text-matching\": Specifies the given text is used for Semantic Textual Similarity.\n- \"classification\": Specifies that the embedding is used for classification.\n- \"separation\": Specifies that the embedding is used for clustering.\n"
          },
          "dimensions": {
            "type": "integer",
            "title": "Dimensions",
            "description": "Used to specify output embedding size. If set, output embeddings will be truncated to the size specified."
          }
        },
        "additionalProperties": false,
        "type": "object",
        "required": [
          "model",
          "input"
        ],
        "title": "ImageEmbeddingInput",
        "description": "The input to the API for text embedding. OpenAI compatible",
        "example": {
          "model": "jina-clip-v1",
          "input": [
            "bytes or URL"
          ]
        }
      },
      "MixedEmbeddingInput": {
        "properties": {
          "model": {
            "type": "string",
            "title": "Model",
            "description": "The identifier of the model.\n\nAvailable models and corresponding param size and dimension:\n- `jina-clip-v1`,\t223M,\t768\n- `jina-clip-v2`,\t865M,\t1024\n\nFor more information, please checkout our [technical blog](https://arxiv.org/abs/2405.20204).\n"
          },
          "input": {
            "items": {
              "anyOf": [
                {
                  "$ref": "#/components/schemas/api_schemas__image__ImageDoc"
                },
                {
                  "$ref": "#/components/schemas/api_schemas__embedding__TextDoc"
                },
                {
                  "type": "string"
                }
              ]
            },
            "type": "array",
            "title": "Input",
            "description": "List of text and images to embed"
          },
          "embedding_type": {
            "anyOf": [
              {
                "type": "string",
                "enum": [
                  "float",
                  "base64",
                  "binary",
                  "ubinary"
                ]
              },
              {
                "items": {
                  "type": "string",
                  "enum": [
                    "float",
                    "base64",
                    "binary",
                    "ubinary"
                  ]
                },
                "type": "array"
              }
            ],
            "title": "Embedding Type",
            "description": "The format in which you want the embeddings to be returned.Possible value are `float`, `base64`, `binary`, `ubinary` or a list containing any of them. Defaults to `float`"
          },
          "normalized": {
            "type": "boolean",
            "title": "Normalized",
            "description": "Flag to determine if the embeddings should be normalized to have a unit L2 norm",
            "default": true
          },
          "task": {
            "type": "string",
            "enum": [
              "retrieval.query",
              "retrieval.passage",
              "text-matching",
              "classification",
              "separation"
            ],
            "title": "Task",
            "description": "Used to convey intended downstream application to help the model produce better embeddings. Must be one of the following values:\n- \"retrieval.query\": Specifies the given text is a query in a search or retrieval setting.\n- \"retrieval.passage\": Specifies the given text is a document in a search or retrieval setting.\n- \"text-matching\": Specifies the given text is used for Semantic Textual Similarity.\n- \"classification\": Specifies that the embedding is used for classification.\n- \"separation\": Specifies that the embedding is used for clustering.\n"
          },
          "dimensions": {
            "type": "integer",
            "title": "Dimensions",
            "description": "Used to specify output embedding size. If set, output embeddings will be truncated to the size specified."
          },
          "truncate": {
            "type": "boolean",
            "title": "Truncate",
            "description": "Flag to determine if the text needs to be truncated when exceeding the maximum token length",
            "default": false
          }
        },
        "additionalProperties": false,
        "type": "object",
        "required": [
          "model",
          "input"
        ],
        "title": "MixedEmbeddingInput",
        "description": "The input to the API for text embedding. OpenAI compatible",
        "example": {
          "model": "jina-clip-v1",
          "input": [
            "bytes or URL"
          ]
        }
      },
      "ModelEmbeddingOutput": {
        "properties": {
          "model": {
            "type": "string",
            "title": "Model",
            "description": "The identifier of the model.\n\nAvailable models and corresponding param size and dimension:\n- `jina-embedding-t-en-v1`,\t14m,\t312\n- `jina-embedding-s-en-v1`,\t35m,\t512 (default)\n- `jina-embedding-b-en-v1`,\t110m,\t768\n- `jina-embedding-l-en-v1`,\t330,\t1024\n\nFor more information, please checkout our [technical blog](https://arxiv.org/abs/2307.11224).\n"
          },
          "object": {
            "type": "string",
            "title": "Object",
            "default": "list"
          },
          "data": {
            "items": {

            },
            "type": "array",
            "title": "Data",
            "description": "A list of Embedding Objects returned by the embedding service"
          },
          "usage": {
            "allOf": [
              {
                "$ref": "#/components/schemas/api_schemas__embedding__Usage"
              }
            ],
            "title": "Usage",
            "description": "Total usage of the request. Sums up the usage from each individual input"
          }
        },
        "type": "object",
        "required": [
          "model",
          "data",
          "usage"
        ],
        "title": "ModelEmbeddingOutput",
        "description": "Output of the embedding service",
        "example": {
          "data": [
            {
              "index": 0,
              "embedding": [0.1, 0.2, 0.3],
              "object": "embedding"
            },
            {
              "index": 1,
              "embedding": [0.3, 0.2, 0.1],
              "object": "embedding"
            }
          ],
          "usage": {
            "total_tokens": 15
          }
        }
      },
      "TextEmbeddingAPIInput": {
        "properties": {
          "model": {
            "type": "string",
            "title": "Model",
            "description": "The identifier of the model.\n\nAvailable models and corresponding param size and dimension:\n- `jina-colbert-v1-en`,\t137\n"
          },
          "input": {
            "anyOf": [
              {
                "items": {
                  "type": "string"
                },
                "type": "array"
              },
              {
                "type": "string"
              },
              {
                "items": {
                  "$ref": "#/components/schemas/api_schemas__embedding__TextDoc"
                },
                "type": "array"
              },
              {
                "$ref": "#/components/schemas/api_schemas__embedding__TextDoc"
              }
            ],
            "title": "Input",
            "description": "List of texts to embed"
          },
          "input_type": {
            "type": "string",
            "enum": [
              "query",
              "document"
            ],
            "title": "Input Type",
            "description": "Type of the embedding to compute, query or document",
            "default": "document"
          },
          "embedding_type": {
            "anyOf": [
              {
                "type": "string",
                "enum": [
                  "float",
                  "base64",
                  "binary",
                  "ubinary"
                ]
              },
              {
                "items": {
                  "type": "string",
                  "enum": [
                    "float",
                    "base64",
                    "binary",
                    "ubinary"
                  ]
                },
                "type": "array"
              }
            ],
            "title": "Embedding Type",
            "description": "The format in which you want the embeddings to be returned.Possible value are `float`, `base64`, `binary`, `ubinary` or a list containing any of them. Defaults to `float`"
          },
          "dimensions": {
            "type": "integer",
            "enum": [64, 96, 128],
            "title": "Dimensions",
            "description": "Dimensions of the vectors to be returned. Only valid for v2 colbert models. Defaults to 128"
          }
        },
        "additionalProperties": false,
        "type": "object",
        "required": [
          "model",
          "input"
        ],
        "title": "TextEmbeddingAPIInput",
        "description": "The input to the API for text embedding. OpenAI compatible",
        "example": {
          "model": "jina-colbert-v1-en",
          "input": [
            "Hello, world!"
          ]
        }
      },
      "ColbertModelEmbeddingsOutput": {
        "properties": {
          "model": {
            "type": "string",
            "title": "Model",
            "description": "The identifier of the model.\n\nAvailable models and corresponding param size and dimension:\n- `jina-embedding-t-en-v1`,\t14m,\t312\n- `jina-embedding-s-en-v1`,\t35m,\t512 (default)\n- `jina-embedding-b-en-v1`,\t110m,\t768\n- `jina-embedding-l-en-v1`,\t330,\t1024\n\nFor more information, please checkout our [technical blog](https://arxiv.org/abs/2307.11224).\n"
          },
          "object": {
            "type": "string",
            "title": "Object",
            "default": "list"
          },
          "data": {
            "items": {

            },
            "type": "array",
            "title": "Data",
            "description": "A list of Embedding Objects returned by the embedding service"
          },
          "usage": {
            "allOf": [
              {
                "$ref": "#/components/schemas/api_schemas__multi_embeddings__Usage"
              }
            ],
            "title": "Usage",
            "description": "Total usage of the request. Sums up the usage from each individual input"
          }
        },
        "type": "object",
        "required": [
          "model",
          "data",
          "usage"
        ],
        "title": "ColbertModelEmbeddingsOutput",
        "description": "Output of the embedding service",
        "example": {
          "data": [
            {
              "index": 0,
              "embeddings": [
                [0.1, 0.2, 0.3],
                [0.4, 0.5, 0.6]
              ],
              "object": "embeddings"
            },
            {
              "index": 1,
              "embeddings": [
                [0.6, 0.5, 0.4],
                [0.3, 0.2, 0.1]
              ],
              "object": "embeddings"
            }
          ],
          "usage": {
            "total_tokens": 15
          }
        }
      },
      "RankAPIInput": {
        "properties": {
          "model": {
            "type": "string",
            "title": "Model",
            "description": "The identifier of the model.\n\nAvailable models and corresponding param size and dimension:\n- `jina-reranker-m0`,\t2B\n- `jina-reranker-v2-base-multilingual`,\t278M\n- `jina-reranker-v1-base-en`,\t137M\n- `jina-reranker-v1-tiny-en`,\t33M\n- `jina-reranker-v1-turbo-en`,\t38M\n- `jina-colbert-v1-en`,\t137M\n"
          },
          "query": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "$ref": "#/components/schemas/api_schemas__rank__TextDoc"
              },
              {
                "$ref": "#/components/schemas/api_schemas__image__ImageDoc"
              }
            ],
            "title": "Query",
            "description": "The search query"
          },
          "documents": {
            "items": {
              "anyOf": [
                {
                  "$ref": "#/components/schemas/api_schemas__image__ImageDoc"
                },
                {
                  "$ref": "#/components/schemas/api_schemas__rank__TextDoc"
                },
                {
                  "type": "string"
                },
                {
                  "$ref": "#/components/schemas/TextOrImageDoc"
                }
              ]
            },
            "type": "array",
            "title": "Documents",
            "description": "A list of text documents, image documents or strings to rerank. If a document is provided the text or image fields are required and all other fields will be preserved in the response."
          },
          "top_n": {
            "type": "integer",
            "title": "Top N",
            "description": "The number of most relevant documents or indices to return, defaults to the length of `documents`"
          },
          "return_documents": {
            "type": "boolean",
            "title": "Return Documents",
            "description": "If false, returns results without the doc text - the api will return a list of {index, relevance score} where index is inferred from the list passed into the request. If true, returns results with the doc text passed in - the api will return an ordered list of {index, text, relevance score} where index + text refers to the list passed into the request. Defaults to true",
            "default": true
          }
        },
        "additionalProperties": false,
        "type": "object",
        "required": [
          "model",
          "query",
          "documents"
        ],
        "title": "RankAPIInput",
        "description": "The input to the API for text embedding. OpenAI compatible",
        "example": {
          "model": "jina-reranker-v2-base-multilingual",
          "query": "Search query",
          "documents": [
            "Document to rank 1",
            "Document to rank 2"
          ]
        }
      },
      "RankingOutput": {
        "properties": {
          "model": {
            "type": "string",
            "title": "Model",
            "description": "The identifier of the model.\n\nAvailable models and corresponding param size and dimension:\n- `jina-embedding-t-en-v1`,\t14m,\t312\n- `jina-embedding-s-en-v1`,\t35m,\t512 (default)\n- `jina-embedding-b-en-v1`,\t110m,\t768\n- `jina-embedding-l-en-v1`,\t330,\t1024\n\nFor more information, please checkout our [technical blog](https://arxiv.org/abs/2307.11224).\n"
          },
          "results": {
            "items": {

            },
            "type": "array",
            "title": "Results",
            "description": "An ordered list of ranked documents"
          },
          "usage": {
            "allOf": [
              {
                "$ref": "#/components/schemas/api_schemas__rank__Usage"
              }
            ],
            "title": "Usage",
            "description": "Total usage of the request."
          }
        },
        "type": "object",
        "required": [
          "model",
          "results",
          "usage"
        ],
        "title": "RankingOutput",
        "description": "Output of the embedding service",
        "example": {
          "results": [
            {
              "index": 0,
              "document": {
                "text": "Document to rank 1"
              },
              "relevance_score": 0.9
            },
            {
              "index": 1,
              "document": {
                "text": "Document to rank 2"
              },
              "relevance_score": 0.8
            }
          ],
          "usage": {
            "total_tokens": 15,
            "prompt_tokens": 15
          }
        }
      },
      "HTTPValidationError": {
        "properties": {
          "detail": {
            "items": {
              "$ref": "#/components/schemas/ValidationError"
            },
            "type": "array",
            "title": "Detail"
          }
        },
        "type": "object",
        "title": "HTTPValidationError"
      },
      "ValidationError": {
        "properties": {
          "loc": {
            "items": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "integer"
                }
              ]
            },
            "type": "array",
            "title": "Location"
          },
          "msg": {
            "type": "string",
            "title": "Message"
          },
          "type": {
            "type": "string",
            "title": "Error Type"
          }
        },
        "type": "object",
        "required": [
          "loc",
          "msg",
          "type"
        ],
        "title": "ValidationError"
      },
      "api_schemas__embedding__TextDoc": {
        "properties": {
          "id": {
            "type": "string",
            "title": "Id",
            "description": "The ID of the BaseDoc. This is useful for indexing in vector stores. If not set by user, it will automatically be assigned a random value",
            "example": "ad9d60e9416e77885fe6dbf272cb7471"
          },
          "text": {
            "type": "string",
            "title": "Text"
          }
        },
        "type": "object",
        "required": [
          "text"
        ],
        "title": "TextDoc",
        "description": "Document containing a text field"
      },
      "api_schemas__embedding__Usage": {
        "properties": {
          "total_tokens": {
            "type": "integer",
            "title": "Total Tokens",
            "description": "The number of tokens used by all the texts in the input"
          },
          "prompt_tokens": {
            "type": "integer",
            "title": "Prompt Tokens",
            "description": "The number of tokens used by all the texts in the input"
          }
        },
        "type": "object",
        "required": [
          "total_tokens",
          "prompt_tokens"
        ],
        "title": "Usage"
      },
      "api_schemas__image__ImageDoc": {
        "properties": {
          "id": {
            "type": "string",
            "title": "Id",
            "description": "The ID of the BaseDoc. This is useful for indexing in vector stores. If not set by user, it will automatically be assigned a random value",
            "example": "ad9d60e9416e77885fe6dbf272cb7471"
          },
          "url": {
            "type": "string",
            "maxLength": 65536,
            "minLength": 1,
            "format": "uri",
            "title": "Url",
            "description": "URL of an image file"
          },
          "bytes": {
            "type": "string",
            "format": "binary",
            "title": "Bytes",
            "description": "base64 representation of the Image."
          },
          "image": {
            "anyOf": [
              {
                "type": "string",
                "maxLength": 65536,
                "minLength": 1,
                "format": "uri"
              },
              {
                "type": "string",
                "format": "binary"
              }
            ],
            "title": "Image",
            "description": "Image representation that can hold URL of an image or a base64 representation"
          }
        },
        "type": "object",
        "title": "ImageDoc",
        "description": "ImageDoc with fields"
      },
      "api_schemas__multi_embeddings__Usage": {
        "properties": {
          "total_tokens": {
            "type": "integer",
            "title": "Total Tokens",
            "description": "The number of tokens used by all the texts in the input"
          }
        },
        "type": "object",
        "required": [
          "total_tokens"
        ],
        "title": "Usage"
      },
      "api_schemas__rank__TextDoc": {
        "properties": {
          "id": {
            "type": "string",
            "title": "Id",
            "description": "The ID of the BaseDoc. This is useful for indexing in vector stores. If not set by user, it will automatically be assigned a random value",
            "example": "ad9d60e9416e77885fe6dbf272cb7471"
          },
          "text": {
            "type": "string",
            "title": "Text"
          }
        },
        "type": "object",
        "required": [
          "text"
        ],
        "title": "TextDoc",
        "description": "Document containing a text field"
      },
      "api_schemas__rank__Usage": {
        "properties": {
          "total_tokens": {
            "type": "integer",
            "title": "Total Tokens",
            "description": "The number of tokens used by all the texts in the input"
          }
        },
        "type": "object",
        "required": [
          "total_tokens"
        ],
        "title": "Usage",
        "example": {
          "total_tokens": 15
        }
      },
      "TextOrImageDoc": {
        "properties": {
          "id": {
            "type": "string",
            "title": "Id",
            "description": "The ID of the BaseDoc. This is useful for indexing in vector stores. If not set by user, it will automatically be assigned a random value",
            "example": "ad9d60e9416e77885fe6dbf272cb7471"
          },
          "text": {
            "type": "string",
            "title": "Text"
          },
          "url": {
            "type": "string",
            "maxLength": 65536,
            "minLength": 1,
            "format": "uri",
            "title": "Url",
            "description": "URL of an image file"
          },
          "bytes": {
            "type": "string",
            "format": "binary",
            "title": "Bytes",
            "description": "base64 representation of the Image."
          },
          "image": {
            "anyOf": [
              {
                "type": "string",
                "maxLength": 65536,
                "minLength": 1,
                "format": "uri"
              },
              {
                "type": "string",
                "format": "binary"
              }
            ],
            "title": "Image",
            "description": "Image representation that can hold URL of an image or a base64 representation"
          }
        },
        "type": "object",
        "title": "TextOrImageDoc",
        "description": "BaseDoc is the base class for all Documents. This class should be subclassed\nto create new Document types with a specific schema.\n\nThe schema of a Document is defined by the fields of the class.\n\nExample:\n```python\nfrom docarray import BaseDoc\nfrom docarray.typing import NdArray, ImageUrl\nimport numpy as np\n\n\nclass MyDoc(BaseDoc):\n    embedding: NdArray[512]\n    image: ImageUrl\n\n\ndoc = MyDoc(embedding=np.zeros(512), image='https://example.com/image.jpg')\n```\n\n\nBaseDoc is a subclass of [pydantic.BaseModel](\nhttps://docs.pydantic.dev/usage/models/) and can be used in a similar way."
      }
    },
    "securitySchemes": {
      "HTTPBearer": {
        "type": "http",
        "scheme": "bearer"
      }
    }
  }
}